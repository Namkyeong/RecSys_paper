{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select GPU Number\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if cuda available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.manual_seed(315)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(912)\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_deep.pkl', 'rb') as f:\n",
    "    df_deep = pickle.load(f)\n",
    "    \n",
    "with open('df_wide.pkl', 'rb') as f:\n",
    "    df_wide = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Data\n",
    "movielens 데이터는 unwatched 데이터가 존재하지 않으므로,  \n",
    "1, 2, 3 을 비선호로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(df_wide[\"rating\"])\n",
    "df_deep = df_deep.drop(columns = [\"rating\"])\n",
    "df_wide = df_wide.drop(columns = [\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_new = np.where(Y == 1, 0, Y)\n",
    "Y_new = np.where(Y_new == 2, 0, Y_new)\n",
    "Y_new = np.where(Y_new == 3, 0, Y_new)\n",
    "Y_new = np.where(Y_new == 4, 1, Y_new)\n",
    "Y_new = np.where(Y_new == 5, 1, Y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0 424928]\n",
      " [     1 575281]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(Y_new, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_deep, X_test_deep = train_test_split(df_deep.values, test_size=0.3, random_state=1981)\n",
    "X_train_wide, X_test_wide = train_test_split(df_wide.values, test_size=0.3, random_state=1981)\n",
    "Y_train, Y_test = train_test_split(Y_new, test_size=0.3, random_state=1981)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    torch.utils.data.Dataset 상속\n",
    "    \"\"\"\n",
    "    def __init__(self, X_wide_tensor, X_deep_tensor, y_tensor):\n",
    "        self.X_wide_tensor = X_wide_tensor\n",
    "        self.X_deep_tensor = X_deep_tensor\n",
    "        self.y_tensor = y_tensor\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X_wide_tensor.size(0)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_wide_tensor[index], self.X_deep_tensor[index], self.y_tensor[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RatingDataset(X_wide_tensor = torch.FloatTensor(X_train_wide),\n",
    "                               X_deep_tensor = torch.LongTensor(X_train_deep),\n",
    "                               y_tensor = torch.FloatTensor(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "test_wide_tensor = torch.FloatTensor(X_test_wide)\n",
    "test_deep_tensor = torch.LongTensor(X_test_deep)\n",
    "test_tensor = torch.FloatTensor(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter(logdir=\"runs/Wide_Deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wide_deep(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(wide_deep, self).__init__()\n",
    "        \n",
    "        # deep model\n",
    "        self.embed_user = nn.Embedding(num_embeddings = 6041, embedding_dim = 32)\n",
    "        self.embed_movie = nn.Embedding(num_embeddings = 3953, embedding_dim = 32)\n",
    "        self.embed_genre = nn.Embedding(num_embeddings = 18, embedding_dim = 8)\n",
    "        self.embed_gender = nn.Embedding(num_embeddings = 2, embedding_dim = 8)\n",
    "        self.embed_age = nn.Embedding(num_embeddings = 7, embedding_dim = 8)\n",
    "        self.embed_occupation = nn.Embedding(num_embeddings = 21, embedding_dim = 8)\n",
    "        \n",
    "        self.linear_1 = nn.Linear(in_features = 96, out_features = 64)\n",
    "        self.linear_2 = nn.Linear(in_features = 64, out_features = 32)\n",
    "        self.linear_3 = nn.Linear(in_features = 32, out_features = 16)\n",
    "        \n",
    "        # wide deep model\n",
    "        self.linear = nn.Linear(in_features = 243, out_features = 1)\n",
    "        self.logistic = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, X_w, X_d):\n",
    "        \n",
    "        # deep model\n",
    "        user_embedding = self.embed_user(X_d[:, 0])\n",
    "        movie_embedding = self.embed_movie(X_d[:, 1])\n",
    "        genre_embedding = self.embed_genre(X_d[:, 2])\n",
    "        gender_embedding = self.embed_gender(X_d[:, 4])\n",
    "        age_embedding = self.embed_age(X_d[:, 5])\n",
    "        occupation_embedding = self.embed_occupation(X_d[:, 6])\n",
    "        \n",
    "        vector = torch.cat([user_embedding, movie_embedding, genre_embedding, gender_embedding, age_embedding, occupation_embedding], dim=-1)\n",
    "        \n",
    "        vector = self.linear_1(vector)\n",
    "        vector = nn.ReLU()(vector)\n",
    "        vector = self.linear_2(vector)\n",
    "        vector = nn.ReLU()(vector)\n",
    "        vector = self.linear_3(vector)\n",
    "        deep_out = nn.ReLU()(vector)\n",
    "        \n",
    "        # integrated\n",
    "        wide_deep_input = torch.cat([X_w, deep_out], dim=1)\n",
    "        logits = self.linear(wide_deep_input)\n",
    "        out = self.logistic(logits)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "    def init_weight(self):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = wide_deep().cuda()\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.001)\n",
    "loss_function = nn.BCELoss()\n",
    "batch_size = 64\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 100, training Loss: 7323.4688, auc score: 0.6136\n",
      "Epoch 2 of 100, training Loss: 7221.3262, auc score: 0.6266\n",
      "Epoch 3 of 100, training Loss: 7171.6807, auc score: 0.6351\n",
      "Epoch 4 of 100, training Loss: 7134.5322, auc score: 0.6417\n",
      "Epoch 5 of 100, training Loss: 7102.7769, auc score: 0.6473\n",
      "Epoch 6 of 100, training Loss: 7073.9858, auc score: 0.6521\n",
      "Epoch 7 of 100, training Loss: 7047.3140, auc score: 0.6567\n",
      "Epoch 8 of 100, training Loss: 7022.1821, auc score: 0.6607\n",
      "Epoch 9 of 100, training Loss: 6998.4277, auc score: 0.6643\n",
      "Epoch 10 of 100, training Loss: 6975.9180, auc score: 0.6678\n",
      "Epoch 11 of 100, training Loss: 6954.7417, auc score: 0.6709\n",
      "Epoch 12 of 100, training Loss: 6934.6533, auc score: 0.6738\n",
      "Epoch 13 of 100, training Loss: 6915.7217, auc score: 0.6765\n",
      "Epoch 14 of 100, training Loss: 6897.8477, auc score: 0.6790\n",
      "Epoch 15 of 100, training Loss: 6880.8340, auc score: 0.6812\n",
      "Epoch 16 of 100, training Loss: 6864.7476, auc score: 0.6834\n",
      "Epoch 17 of 100, training Loss: 6849.5918, auc score: 0.6854\n",
      "Epoch 18 of 100, training Loss: 6835.2046, auc score: 0.6873\n",
      "Epoch 19 of 100, training Loss: 6821.4824, auc score: 0.6890\n",
      "Epoch 20 of 100, training Loss: 6808.5049, auc score: 0.6907\n",
      "Epoch 21 of 100, training Loss: 6796.1421, auc score: 0.6922\n",
      "Epoch 22 of 100, training Loss: 6784.3057, auc score: 0.6937\n",
      "Epoch 23 of 100, training Loss: 6772.9731, auc score: 0.6951\n",
      "Epoch 24 of 100, training Loss: 6762.1802, auc score: 0.6965\n",
      "Epoch 25 of 100, training Loss: 6751.8203, auc score: 0.6977\n",
      "Epoch 26 of 100, training Loss: 6741.8892, auc score: 0.6989\n",
      "Epoch 27 of 100, training Loss: 6732.2632, auc score: 0.7001\n",
      "Epoch 28 of 100, training Loss: 6723.1157, auc score: 0.7012\n",
      "Epoch 29 of 100, training Loss: 6714.2100, auc score: 0.7022\n",
      "Epoch 30 of 100, training Loss: 6705.6533, auc score: 0.7032\n",
      "Epoch 31 of 100, training Loss: 6697.3433, auc score: 0.7042\n",
      "Epoch 32 of 100, training Loss: 6689.2300, auc score: 0.7051\n",
      "Epoch 33 of 100, training Loss: 6681.5708, auc score: 0.7060\n",
      "Epoch 34 of 100, training Loss: 6673.9844, auc score: 0.7069\n",
      "Epoch 35 of 100, training Loss: 6666.7754, auc score: 0.7078\n",
      "Epoch 36 of 100, training Loss: 6659.7051, auc score: 0.7086\n",
      "Epoch 37 of 100, training Loss: 6652.7690, auc score: 0.7094\n",
      "Epoch 38 of 100, training Loss: 6646.1133, auc score: 0.7101\n",
      "Epoch 39 of 100, training Loss: 6639.6021, auc score: 0.7109\n",
      "Epoch 40 of 100, training Loss: 6633.2534, auc score: 0.7116\n",
      "Epoch 41 of 100, training Loss: 6627.0537, auc score: 0.7123\n",
      "Epoch 42 of 100, training Loss: 6621.0298, auc score: 0.7129\n",
      "Epoch 43 of 100, training Loss: 6615.0703, auc score: 0.7136\n",
      "Epoch 44 of 100, training Loss: 6609.3110, auc score: 0.7142\n",
      "Epoch 45 of 100, training Loss: 6603.7100, auc score: 0.7148\n",
      "Epoch 46 of 100, training Loss: 6598.2505, auc score: 0.7154\n",
      "Epoch 47 of 100, training Loss: 6592.8691, auc score: 0.7160\n",
      "Epoch 48 of 100, training Loss: 6587.6372, auc score: 0.7166\n",
      "Epoch 49 of 100, training Loss: 6582.4902, auc score: 0.7172\n",
      "Epoch 50 of 100, training Loss: 6577.3540, auc score: 0.7177\n",
      "Epoch 51 of 100, training Loss: 6572.4575, auc score: 0.7182\n",
      "Epoch 52 of 100, training Loss: 6567.6411, auc score: 0.7188\n",
      "Epoch 53 of 100, training Loss: 6562.8501, auc score: 0.7193\n",
      "Epoch 54 of 100, training Loss: 6558.1904, auc score: 0.7198\n",
      "Epoch 55 of 100, training Loss: 6553.6382, auc score: 0.7202\n",
      "Epoch 56 of 100, training Loss: 6549.1235, auc score: 0.7207\n",
      "Epoch 57 of 100, training Loss: 6544.6753, auc score: 0.7212\n",
      "Epoch 58 of 100, training Loss: 6540.3452, auc score: 0.7216\n",
      "Epoch 59 of 100, training Loss: 6536.0493, auc score: 0.7221\n",
      "Epoch 60 of 100, training Loss: 6531.8926, auc score: 0.7225\n",
      "Epoch 61 of 100, training Loss: 6527.7256, auc score: 0.7229\n",
      "Epoch 62 of 100, training Loss: 6523.6460, auc score: 0.7234\n",
      "Epoch 63 of 100, training Loss: 6519.6943, auc score: 0.7238\n",
      "Epoch 64 of 100, training Loss: 6515.7339, auc score: 0.7242\n",
      "Epoch 65 of 100, training Loss: 6511.8232, auc score: 0.7246\n",
      "Epoch 66 of 100, training Loss: 6508.0483, auc score: 0.7250\n",
      "Epoch 67 of 100, training Loss: 6504.2832, auc score: 0.7254\n",
      "Epoch 68 of 100, training Loss: 6500.5894, auc score: 0.7257\n",
      "Epoch 69 of 100, training Loss: 6496.9580, auc score: 0.7261\n",
      "Epoch 70 of 100, training Loss: 6493.3394, auc score: 0.7265\n",
      "Epoch 71 of 100, training Loss: 6489.7920, auc score: 0.7268\n",
      "Epoch 72 of 100, training Loss: 6486.2612, auc score: 0.7272\n",
      "Epoch 73 of 100, training Loss: 6482.8740, auc score: 0.7275\n",
      "Epoch 74 of 100, training Loss: 6479.4854, auc score: 0.7279\n",
      "Epoch 75 of 100, training Loss: 6476.0869, auc score: 0.7282\n",
      "Epoch 76 of 100, training Loss: 6472.8115, auc score: 0.7286\n",
      "Epoch 77 of 100, training Loss: 6469.5435, auc score: 0.7289\n",
      "Epoch 78 of 100, training Loss: 6466.3105, auc score: 0.7292\n",
      "Epoch 79 of 100, training Loss: 6463.1514, auc score: 0.7295\n",
      "Epoch 80 of 100, training Loss: 6460.0190, auc score: 0.7298\n",
      "Epoch 81 of 100, training Loss: 6456.8555, auc score: 0.7301\n",
      "Epoch 82 of 100, training Loss: 6453.8174, auc score: 0.7304\n",
      "Epoch 83 of 100, training Loss: 6450.8018, auc score: 0.7307\n",
      "Epoch 84 of 100, training Loss: 6447.8213, auc score: 0.7310\n",
      "Epoch 85 of 100, training Loss: 6444.8887, auc score: 0.7313\n",
      "Epoch 86 of 100, training Loss: 6441.9790, auc score: 0.7316\n",
      "Epoch 87 of 100, training Loss: 6439.0864, auc score: 0.7319\n",
      "Epoch 88 of 100, training Loss: 6436.2222, auc score: 0.7322\n",
      "Epoch 89 of 100, training Loss: 6433.3125, auc score: 0.7324\n",
      "Epoch 90 of 100, training Loss: 6430.5972, auc score: 0.7327\n",
      "Epoch 91 of 100, training Loss: 6427.8198, auc score: 0.7330\n",
      "Epoch 92 of 100, training Loss: 6425.1069, auc score: 0.7332\n",
      "Epoch 93 of 100, training Loss: 6422.4111, auc score: 0.7335\n",
      "Epoch 94 of 100, training Loss: 6419.7612, auc score: 0.7337\n",
      "Epoch 95 of 100, training Loss: 6417.1362, auc score: 0.7340\n",
      "Epoch 96 of 100, training Loss: 6414.5415, auc score: 0.7342\n",
      "Epoch 97 of 100, training Loss: 6411.9556, auc score: 0.7345\n",
      "Epoch 98 of 100, training Loss: 6409.3853, auc score: 0.7347\n",
      "Epoch 99 of 100, training Loss: 6406.8330, auc score: 0.7350\n",
      "Epoch 100 of 100, training Loss: 6404.3477, auc score: 0.7352\n"
     ]
    }
   ],
   "source": [
    "for epoch_id in range(n_epochs):\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "\n",
    "        X_w, X_d, y = batch[0], batch[1], batch[2]\n",
    "        X_w, X_d, y = X_w.cuda(), X_d.cuda(), y.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_w, X_d)\n",
    "        loss = loss_function(y_pred.view(-1), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "        \n",
    "    model.eval()\n",
    "    pred = model(test_wide_tensor.cuda(), test_deep_tensor.cuda())\n",
    "    auc = roc_auc_score(test_tensor.cpu().detach().numpy(), pred.cpu().detach().numpy())\n",
    "    \n",
    "    writer.add_scalar(\"loss/ Train_loss\", total_loss, epoch_id)\n",
    "    writer.add_scalar(\"performace/AUC\", auc, epoch_id)\n",
    "\n",
    "    print ('Epoch {} of {}, training Loss: {:.4f}, auc score: {:.4f}'.format(epoch_id + 1, n_epochs, total_loss, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mf_v1",
   "language": "python",
   "name": "mf_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
