{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/namkyeong/Wide_Deep/dataframe.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_ratings = pd.read_csv(\"./ml-1m/ratings.dat\", sep=\"::\", names=['userId', 'movieId', 'rating', 'timestamp'])\n",
      "/home/namkyeong/Wide_Deep/dataframe.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_movies = pd.read_table(\"./ml-1m/movies.dat\", sep=\"::\", names=[\"movieId\",\"movie_name\", \"genre\"], encoding = \"latin-1\")\n",
      "/home/namkyeong/Wide_Deep/dataframe.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_users = pd.read_table(\"./ml-1m/users.dat\", sep=\"::\", names=[\"userId\", \"gender\", \"age\", \"occupation\", \"zipcode\"])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframe.final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_cols = [\"userId\", \"movieId\", \"genre\", \"movie_year\", \"gender\", \"age\", \"occupation\"]\n",
    "crossed_cols = ([\"gender\", \"genre\"], [\"gender\", \"age\"], [\"age\", \"genre\"])\n",
    "embeddings_cols = [\"userId\", \"movieId\", \"genre\", \"gender\", \"age\", \"occupation\"]\n",
    "continuous_cols = [\"movie_year\"]\n",
    "target = \"rating\"\n",
    "\n",
    "df['age'] = df.apply(lambda row : str(row[\"age\"]),axis=1)\n",
    "df['occupation'] = df.apply(lambda row : str(row[\"occupation\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(df[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datset for Wide Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = df.copy()\n",
    "\n",
    "# Build the crossed columns\n",
    "crossed_columns = []\n",
    "for cols in crossed_cols:\n",
    "    colname = '_'.join(cols)\n",
    "    df_wide[colname] = df_wide[cols].apply(lambda x: '-'.join(x), axis=1)\n",
    "    crossed_columns.append(colname)\n",
    "    \n",
    "categorical_columns = list(df_wide.select_dtypes(include=['object']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "for cc in [\"userId\", \"movieId\", \"movie_year\"]:\n",
    "    df_wide[cc]  = scaler.fit_transform(df_wide[cc].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cols = [c for c in wide_cols+crossed_columns if c in categorical_columns]\n",
    "df_wide = pd.get_dummies(df_wide, columns=dummy_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"df_wide.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df_wide, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset for Deep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deep = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(df, cols=None):\n",
    "    if cols == None:\n",
    "        cols = list(df.select_dtypes(include=['object']).columns)\n",
    "\n",
    "    val_types = dict()\n",
    "    for c in cols:\n",
    "        val_types[c] = df[c].unique()\n",
    "\n",
    "    val_to_idx = dict()\n",
    "    for k, v in val_types.items():\n",
    "        val_to_idx[k] = {o: i for i, o in enumerate(val_types[k])}\n",
    "\n",
    "    for k, v in val_to_idx.items():\n",
    "        df[k] = df[k].apply(lambda x: v[x])\n",
    "\n",
    "    return val_to_idx, df\n",
    "\n",
    "val_to_idx, df_deep = encoder(df_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_deep[\"movie_year\"]  = scaler.fit_transform(df_deep[\"movie_year\"].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"df_deep.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df_deep, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mf_v1",
   "language": "python",
   "name": "mf_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
