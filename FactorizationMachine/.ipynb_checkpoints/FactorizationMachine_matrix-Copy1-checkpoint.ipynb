{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/namkyeong/anaconda3/envs/mf_v1/lib/python3.7/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "df = pd.read_csv(\"./ml-1m/ratings.dat\", sep ='::' , names=r_cols )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=1981)\n",
    "df_train = df_train.reset_index()\n",
    "df_test = df_test.reset_index()\n",
    "df_train = df_train.drop([\"index\"], axis = 1)\n",
    "df_test = df_test.drop([\"index\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = data.create_dataset(df_train)\n",
    "test_x, test_y = data.create_dataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select GPU Number\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if cuda available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.manual_seed(315)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(912)\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensDataset(Dataset):\n",
    "    \"\"\"\n",
    "    torch.utils.data.Dataset 상속\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MovielensDataset(X = torch.FloatTensor(train_x),\n",
    "                                y = torch.FloatTensor(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorizationMachine(nn.Module):\n",
    "    \n",
    "    def __init__(self, field_dims, latent_dims):\n",
    "        super(FactorizationMachine, self).__init__()\n",
    "        \n",
    "        self.w_0 = nn.Parameter(nn.init.normal_(torch.zeros((1, ))), requires_grad=True) #(1, )\n",
    "        self.w_i = nn.Parameter(nn.init.normal_(torch.zeros((1, field_dims)), std=1.0/field_dims), requires_grad = True) # (1, 4308)\n",
    "        self.V = nn.Parameter(nn.init.normal_(torch.zeros((field_dims, latent_dims)), std=1.0/latent_dims), requires_grad = True) # (4308, 40)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        batch shape (64, 4308)\n",
    "        \"\"\"\n",
    "        temp_1 = self.w_0 + torch.matmul(x, self.w_i.T) # (64, 1)\n",
    "        \n",
    "        square_of_sum = torch.sum(torch.matmul(x, self.V), dim = 1) ** 2\n",
    "        sum_of_square = torch.sum(torch.matmul(x, self.V) ** 2, dim = 1)\n",
    "        temp_2 = (square_of_sum - sum_of_square).view(-1, 1)\n",
    "        \n",
    "        result = temp_1 + 0.5 * temp_2\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def init_weight(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FactorizationMachine(field_dims = train_x.shape[1], latent_dims = 20).cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()\n",
    "batch_size = 64\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 100, training Loss: 16505.3672, test Loss: 1.1063\n",
      "Epoch 2 of 100, training Loss: 15126.5508, test Loss: 1.0934\n",
      "Epoch 3 of 100, training Loss: 14785.4795, test Loss: 1.0820\n",
      "Epoch 4 of 100, training Loss: 14508.1582, test Loss: 1.0730\n",
      "Epoch 5 of 100, training Loss: 14284.5361, test Loss: 1.0653\n",
      "Epoch 6 of 100, training Loss: 14092.6934, test Loss: 1.0586\n",
      "Epoch 7 of 100, training Loss: 13923.1748, test Loss: 1.0527\n",
      "Epoch 8 of 100, training Loss: 13774.0264, test Loss: 1.0475\n",
      "Epoch 9 of 100, training Loss: 13641.5215, test Loss: 1.0429\n",
      "Epoch 10 of 100, training Loss: 13520.5977, test Loss: 1.0386\n",
      "Epoch 11 of 100, training Loss: 13408.0732, test Loss: 1.0345\n",
      "Epoch 12 of 100, training Loss: 13302.2764, test Loss: 1.0308\n",
      "Epoch 13 of 100, training Loss: 13202.6895, test Loss: 1.0272\n",
      "Epoch 14 of 100, training Loss: 13109.5078, test Loss: 1.0239\n",
      "Epoch 15 of 100, training Loss: 13022.0186, test Loss: 1.0207\n",
      "Epoch 16 of 100, training Loss: 12939.6094, test Loss: 1.0178\n",
      "Epoch 17 of 100, training Loss: 12862.0996, test Loss: 1.0150\n",
      "Epoch 18 of 100, training Loss: 12788.3994, test Loss: 1.0123\n",
      "Epoch 19 of 100, training Loss: 12718.7734, test Loss: 1.0098\n",
      "Epoch 20 of 100, training Loss: 12651.9736, test Loss: 1.0074\n",
      "Epoch 21 of 100, training Loss: 12588.4570, test Loss: 1.0051\n",
      "Epoch 22 of 100, training Loss: 12527.3447, test Loss: 1.0028\n",
      "Epoch 23 of 100, training Loss: 12469.1816, test Loss: 1.0007\n",
      "Epoch 24 of 100, training Loss: 12413.5146, test Loss: 0.9987\n",
      "Epoch 25 of 100, training Loss: 12360.0498, test Loss: 0.9967\n",
      "Epoch 26 of 100, training Loss: 12308.6152, test Loss: 0.9948\n",
      "Epoch 27 of 100, training Loss: 12258.9883, test Loss: 0.9930\n",
      "Epoch 28 of 100, training Loss: 12211.4639, test Loss: 0.9912\n",
      "Epoch 29 of 100, training Loss: 12165.7314, test Loss: 0.9895\n",
      "Epoch 30 of 100, training Loss: 12121.5879, test Loss: 0.9878\n",
      "Epoch 31 of 100, training Loss: 12079.0537, test Loss: 0.9863\n",
      "Epoch 32 of 100, training Loss: 12038.1270, test Loss: 0.9847\n",
      "Epoch 33 of 100, training Loss: 11998.2295, test Loss: 0.9833\n",
      "Epoch 34 of 100, training Loss: 11960.0312, test Loss: 0.9818\n",
      "Epoch 35 of 100, training Loss: 11923.1318, test Loss: 0.9805\n",
      "Epoch 36 of 100, training Loss: 11887.6611, test Loss: 0.9791\n",
      "Epoch 37 of 100, training Loss: 11852.7705, test Loss: 0.9778\n",
      "Epoch 38 of 100, training Loss: 11819.4941, test Loss: 0.9766\n",
      "Epoch 39 of 100, training Loss: 11787.2363, test Loss: 0.9754\n",
      "Epoch 40 of 100, training Loss: 11755.7236, test Loss: 0.9742\n",
      "Epoch 41 of 100, training Loss: 11725.3555, test Loss: 0.9731\n",
      "Epoch 42 of 100, training Loss: 11695.8096, test Loss: 0.9720\n",
      "Epoch 43 of 100, training Loss: 11667.5332, test Loss: 0.9709\n",
      "Epoch 44 of 100, training Loss: 11639.7178, test Loss: 0.9699\n",
      "Epoch 45 of 100, training Loss: 11613.0449, test Loss: 0.9689\n",
      "Epoch 46 of 100, training Loss: 11586.8467, test Loss: 0.9679\n",
      "Epoch 47 of 100, training Loss: 11561.3535, test Loss: 0.9670\n",
      "Epoch 48 of 100, training Loss: 11536.4990, test Loss: 0.9660\n",
      "Epoch 49 of 100, training Loss: 11512.6904, test Loss: 0.9651\n",
      "Epoch 50 of 100, training Loss: 11489.3271, test Loss: 0.9643\n",
      "Epoch 51 of 100, training Loss: 11466.2949, test Loss: 0.9634\n",
      "Epoch 52 of 100, training Loss: 11444.1523, test Loss: 0.9626\n",
      "Epoch 53 of 100, training Loss: 11422.6641, test Loss: 0.9618\n",
      "Epoch 54 of 100, training Loss: 11401.7168, test Loss: 0.9610\n",
      "Epoch 55 of 100, training Loss: 11381.5547, test Loss: 0.9602\n",
      "Epoch 56 of 100, training Loss: 11361.4238, test Loss: 0.9595\n",
      "Epoch 57 of 100, training Loss: 11342.2471, test Loss: 0.9588\n",
      "Epoch 58 of 100, training Loss: 11323.2012, test Loss: 0.9581\n",
      "Epoch 59 of 100, training Loss: 11305.0488, test Loss: 0.9574\n",
      "Epoch 60 of 100, training Loss: 11287.2363, test Loss: 0.9567\n",
      "Epoch 61 of 100, training Loss: 11269.6875, test Loss: 0.9561\n",
      "Epoch 62 of 100, training Loss: 11252.4336, test Loss: 0.9555\n",
      "Epoch 63 of 100, training Loss: 11235.9346, test Loss: 0.9548\n",
      "Epoch 64 of 100, training Loss: 11219.8145, test Loss: 0.9542\n",
      "Epoch 65 of 100, training Loss: 11203.9336, test Loss: 0.9536\n",
      "Epoch 66 of 100, training Loss: 11188.2539, test Loss: 0.9531\n",
      "Epoch 67 of 100, training Loss: 11173.0391, test Loss: 0.9525\n",
      "Epoch 68 of 100, training Loss: 11158.3350, test Loss: 0.9519\n",
      "Epoch 69 of 100, training Loss: 11143.7949, test Loss: 0.9514\n",
      "Epoch 70 of 100, training Loss: 11129.8740, test Loss: 0.9509\n",
      "Epoch 71 of 100, training Loss: 11115.9111, test Loss: 0.9504\n",
      "Epoch 72 of 100, training Loss: 11102.3584, test Loss: 0.9499\n",
      "Epoch 73 of 100, training Loss: 11089.1904, test Loss: 0.9494\n",
      "Epoch 74 of 100, training Loss: 11076.1543, test Loss: 0.9489\n",
      "Epoch 75 of 100, training Loss: 11063.3447, test Loss: 0.9484\n",
      "Epoch 76 of 100, training Loss: 11051.1006, test Loss: 0.9480\n",
      "Epoch 77 of 100, training Loss: 11038.8232, test Loss: 0.9475\n",
      "Epoch 78 of 100, training Loss: 11026.9160, test Loss: 0.9471\n",
      "Epoch 79 of 100, training Loss: 11015.1689, test Loss: 0.9466\n",
      "Epoch 80 of 100, training Loss: 11003.8125, test Loss: 0.9462\n",
      "Epoch 81 of 100, training Loss: 10992.5811, test Loss: 0.9458\n",
      "Epoch 82 of 100, training Loss: 10981.5420, test Loss: 0.9454\n",
      "Epoch 83 of 100, training Loss: 10970.9258, test Loss: 0.9450\n",
      "Epoch 84 of 100, training Loss: 10960.1250, test Loss: 0.9446\n",
      "Epoch 85 of 100, training Loss: 10949.8320, test Loss: 0.9442\n",
      "Epoch 86 of 100, training Loss: 10939.5625, test Loss: 0.9438\n",
      "Epoch 87 of 100, training Loss: 10929.6377, test Loss: 0.9434\n"
     ]
    }
   ],
   "source": [
    "for epoch_id in range(n_epochs):\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "\n",
    "        X, y = batch[0], batch[1]\n",
    "        X, y = X.cuda(), y.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        loss = loss_function(y_pred.view(-1), y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "        \n",
    "    model.eval()\n",
    "    y_test = model(torch.FloatTensor(test_x).cuda())\n",
    "    y_test = y_test.cpu().detach().numpy()\n",
    "    rmse = np.sqrt(np.mean((y_test - test_y)**2))\n",
    "    print ('Epoch {} of {}, training Loss: {:.4f}, test Loss: {:.4f}'.format(epoch_id + 1, n_epochs, total_loss, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mf_v1",
   "language": "python",
   "name": "mf_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
