{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/namkyeong/anaconda3/envs/mf_v1/lib/python3.7/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "df = pd.read_csv(\"./ml-1m/ratings.dat\", sep ='::' , names=r_cols )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=1981)\n",
    "df_train = df_train.reset_index()\n",
    "df_test = df_test.reset_index()\n",
    "df_train = df_train.drop([\"index\"], axis = 1)\n",
    "df_test = df_test.drop([\"index\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = data.create_dataset(df_train)\n",
    "test_x, test_y = data.create_dataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select GPU Number\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if cuda available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.manual_seed(315)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(912)\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensDataset(Dataset):\n",
    "    \"\"\"\n",
    "    torch.utils.data.Dataset 상속\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MovielensDataset(X = torch.FloatTensor(train_x),\n",
    "                                y = torch.FloatTensor(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorizationMachine(nn.Module):\n",
    "    \n",
    "    def __init__(self, field_dims, latent_dims):\n",
    "        super(FactorizationMachine, self).__init__()\n",
    "        \n",
    "        self.w_0 = nn.Parameter(nn.init.normal_(torch.zeros((1, ))), requires_grad=True) #(1, )\n",
    "        self.w_i = nn.Parameter(nn.init.normal_(torch.zeros((1, field_dims)), std=1.0/field_dims), requires_grad = True) # (1, 4308)\n",
    "        self.V = nn.Parameter(nn.init.normal_(torch.zeros((field_dims, latent_dims)), std=1.0/latent_dims), requires_grad = True) # (4308, 40)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        batch shape (64, 4308)\n",
    "        \"\"\"\n",
    "        temp_1 = self.w_0 + torch.matmul(x, self.w_i.T) # (64, 1)\n",
    "        \n",
    "        square_of_sum = torch.sum(torch.matmul(x, self.V), dim = 1) ** 2\n",
    "        sum_of_square = torch.sum(torch.matmul(x, self.V) ** 2, dim = 1)\n",
    "        temp_2 = (square_of_sum - sum_of_square).view(-1, 1)\n",
    "        \n",
    "        result = temp_1 + 0.5 * temp_2\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def init_weight(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FactorizationMachine(field_dims = train_x.shape[1], latent_dims = 20).cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()\n",
    "batch_size = 64\n",
    "n_epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter(logdir=\"runs/FactorizationMachine_MatrixVer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 of 300, training Loss: 13330.3271, RMSE: 1.0318\n",
      "Epoch 20 of 300, training Loss: 12544.8760, RMSE: 1.0035\n",
      "Epoch 30 of 300, training Loss: 12049.4902, RMSE: 0.9852\n",
      "Epoch 40 of 300, training Loss: 11703.4385, RMSE: 0.9723\n",
      "Epoch 50 of 300, training Loss: 11449.9209, RMSE: 0.9628\n",
      "Epoch 60 of 300, training Loss: 11256.7578, RMSE: 0.9556\n",
      "Epoch 70 of 300, training Loss: 11105.7832, RMSE: 0.9500\n",
      "Epoch 80 of 300, training Loss: 10984.4717, RMSE: 0.9455\n",
      "Epoch 90 of 300, training Loss: 10884.5449, RMSE: 0.9418\n",
      "Epoch 100 of 300, training Loss: 10800.2588, RMSE: 0.9386\n",
      "Epoch 110 of 300, training Loss: 10728.3438, RMSE: 0.9359\n",
      "Epoch 120 of 300, training Loss: 10666.7578, RMSE: 0.9336\n",
      "Epoch 130 of 300, training Loss: 10612.6611, RMSE: 0.9317\n",
      "Epoch 140 of 300, training Loss: 10565.9414, RMSE: 0.9299\n",
      "Epoch 150 of 300, training Loss: 10524.3018, RMSE: 0.9284\n",
      "Epoch 160 of 300, training Loss: 10487.5020, RMSE: 0.9271\n",
      "Epoch 170 of 300, training Loss: 10454.6963, RMSE: 0.9259\n",
      "Epoch 180 of 300, training Loss: 10425.1104, RMSE: 0.9249\n",
      "Epoch 190 of 300, training Loss: 10398.4717, RMSE: 0.9240\n",
      "Epoch 200 of 300, training Loss: 10373.8652, RMSE: 0.9231\n",
      "Epoch 210 of 300, training Loss: 10351.6172, RMSE: 0.9223\n",
      "Epoch 220 of 300, training Loss: 10331.0312, RMSE: 0.9216\n",
      "Epoch 230 of 300, training Loss: 10311.9219, RMSE: 0.9210\n",
      "Epoch 240 of 300, training Loss: 10294.3984, RMSE: 0.9204\n",
      "Epoch 250 of 300, training Loss: 10277.9043, RMSE: 0.9199\n",
      "Epoch 260 of 300, training Loss: 10262.6338, RMSE: 0.9194\n",
      "Epoch 270 of 300, training Loss: 10248.1943, RMSE: 0.9189\n",
      "Epoch 280 of 300, training Loss: 10234.8115, RMSE: 0.9185\n",
      "Epoch 290 of 300, training Loss: 10222.2588, RMSE: 0.9181\n",
      "Epoch 300 of 300, training Loss: 10210.4463, RMSE: 0.9177\n"
     ]
    }
   ],
   "source": [
    "for epoch_id in range(n_epochs):\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "\n",
    "        X, y = batch[0], batch[1]\n",
    "        X, y = X.cuda(), y.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        loss = loss_function(y_pred.view(-1), y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    y_test = model(torch.FloatTensor(test_x).cuda())\n",
    "    y_test = y_test.cpu().detach().numpy()\n",
    "    rmse = np.sqrt(np.mean((y_test - test_y)**2))\n",
    "    \n",
    "    writer.add_scalar(\"loss/ Train_loss\", total_loss, epoch_id)\n",
    "    writer.add_scalar(\"performace/RMSE\", rmse, epoch_id)\n",
    "    \n",
    "    if ((epoch_id + 1) % 10 == 0 ):\n",
    "        print ('Epoch {} of {}, training Loss: {:.4f}, RMSE: {:.4f}'.format(epoch_id + 1, n_epochs, total_loss, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mf_v1",
   "language": "python",
   "name": "mf_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
