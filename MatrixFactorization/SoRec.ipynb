{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy data\n",
    "trust=np.array([[0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "            [0.0,0.0,0.0,1.0,0.0,0.8],\n",
    "            [0.8,0.0,0.0,0.0,0.0,0.0],\n",
    "            [0.8,1.0,0.0,0.0,0.6,0.0],\n",
    "            [0.0,0.0,0.4,0.0,0.0,0.8],\n",
    "            [0.0,0.0,0.0,0.0,0.0,0.0]])\n",
    "\n",
    "train=np.array([[5.0,2.0,0.0,3.0,0.0,4.0,0.0,0.0],\n",
    "            [4.0,3.0,0.0,0.0,5.0,0.0,0.0,0.0],\n",
    "            [4.0,0.0,2.0,0.0,0.0,0.0,2.0,4.0],\n",
    "            [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "            [5.0,1.0,2.0,0.0,4.0,3.0,0.0,0.0],\n",
    "            [4.0,3.0,0.0,2.0,4.0,0.0,3.0,5.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = data.train\n",
    "# test = data.test\n",
    "# trust = data.trust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoRec():\n",
    "    \n",
    "    def __init__(self, train, test, trust, dim, learning_rate, epochs, verbose = False):\n",
    "        \"\"\"\n",
    "        param train : Rating Matrix for training\n",
    "        param test : Rating Matrix for Test\n",
    "        param k : latent dimension\n",
    "        param learning_rate : alpha on weight update\n",
    "        param epochs : training epochs\n",
    "        param verbose : print status\n",
    "        \"\"\"\n",
    "        \n",
    "        self.train = train\n",
    "        self.max_rate = train.max()\n",
    "        self.test = test\n",
    "        self.num_users, self.num_items = train.shape\n",
    "        self.trust = trust\n",
    "        self.lambda_C = 0.01\n",
    "        self.lambda_U = 0.01\n",
    "        self.lambda_V = 0.01\n",
    "        self.lambda_Z = 0.01\n",
    "        self.dim = dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        \n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        training Matrix Factorization : update matrix latent weight and bias\n",
    "        \"\"\"\n",
    "        # init latent features\n",
    "        self.U = np.random.normal(scale = 1.0/self.dim, size=(self.num_users, self.dim))\n",
    "        self.V = np.random.normal(scale = 1.0/self.dim, size=(self.num_items, self.dim))\n",
    "        self.Z = np.random.normal(scale = 1.0/self.dim, size=(self.num_users, self.dim))\n",
    "        \n",
    "        self.scale_rate()\n",
    "        self.convert_trust()\n",
    "        \n",
    "        self.training_process = []\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(self.num_users):\n",
    "                for j in range(self.num_items):\n",
    "                    for k in range(self.num_users):\n",
    "                        self.gradient_descent(i, j, k)\n",
    "                        \n",
    "            train_cost, test_cost = self.cost()\n",
    "            self.training_process.append((epoch, train_cost, test_cost))\n",
    "            \n",
    "            if self.verbose == True and ((epoch + 1) % 10 == 0 ):\n",
    "                print(\"Iteration : %d, train_cost = %.4f, test_cost = %.4f\" % (epoch+1, train_cost, test_cost))\n",
    "    \n",
    "    \n",
    "    def convert_trust(self):\n",
    "        \n",
    "        converted_trust = np.zeros((self.num_users, self.num_users))\n",
    "        for i in range(self.num_users):\n",
    "            for k in range(self.num_users):\n",
    "                d_vk = np.count_nonzero(self.trust[:, k])\n",
    "                d_vi = np.count_nonzero(self.trust[i, :])\n",
    "                converted_trust[i, k] = (d_vk / (d_vi + d_vk))**(1/2) * self.trust[i, k] \n",
    "        \n",
    "        self.trust = converted_trust\n",
    "    \n",
    "    # scale ratings between 0 and 1\n",
    "    def scale_rate(self):    \n",
    "        for i in range(self.num_users):\n",
    "            for j in range(self.num_items):\n",
    "                if self.train[i, j] != 0:\n",
    "                    self.train[i, j] = (self.train[i, j] - 1) / (self.max_rate - 1)\n",
    "                    \n",
    "                    \n",
    "    def rescale_rate(self, x):\n",
    "        \n",
    "        return (self.max_rate - 1)*x + 1\n",
    "    \n",
    "    \n",
    "    def logistic(self, x):\n",
    "        \"\"\"\n",
    "        function logistic\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    \n",
    "    def d_logistic(self, x):\n",
    "        \"\"\"\n",
    "        function derivative logistic\n",
    "        \"\"\"\n",
    "        return np.exp(x)/(1+np.exp(x))**2\n",
    "    \n",
    "    \n",
    "    def cost(self):\n",
    "        \"\"\"\n",
    "        compute RMSE\n",
    "        \"\"\"\n",
    "        xi, yi = self.train.nonzero() # 0 이 아닌 값의 index 반환\n",
    "        test_x, test_y = self.test.nonzero()\n",
    "        predicted = self.logistic(self.get_complete_matrix())\n",
    "        cost_train = 0\n",
    "        cost_test = 0\n",
    "        \n",
    "        for x, y in zip(xi, yi):\n",
    "            cost_train += np.abs(self.train[x, y] - predicted[x, y])\n",
    "        \n",
    "        for x, y in zip(test_x, test_y):\n",
    "            cost_test += np.abs(self.test[x, y] - predicted[x, y])\n",
    "        \n",
    "        return cost_train/len(xi), cost_test/len(test_x)\n",
    "    \n",
    "    \n",
    "    def gradient_descent(self, i, j, k):\n",
    "        \"\"\"\n",
    "        gradient descent function\n",
    "        param i : user index\n",
    "        param j : item index\n",
    "        \"\"\"\n",
    "        rating_pred = self.U[i, :].dot(self.V[j, :].T)\n",
    "        trust_pred = self.U[i, :].dot(self.Z[k, :].T)\n",
    "        \n",
    "        if self.trust[i, k] > 0:\n",
    "            self.U[i, :] -= self.learning_rate * self.lambda_C * self.d_logistic(trust_pred)*(self.logistic(trust_pred)-self.trust[i, k])*self.Z[k, :]\n",
    "            self.Z[k, :] -= self.learning_rate * self.lambda_C * self.d_logistic(trust_pred)*(self.logistic(trust_pred)-self.trust[i, k])*self.U[i, :]        \n",
    "        \n",
    "        if self.train[i, j] > 0 :\n",
    "            self.U[i, :] -= self.learning_rate * (self.d_logistic(rating_pred)*(self.logistic(rating_pred)-self.train[i, j])*self.V[j, :])\n",
    "            self.V[j, :] -= self.learning_rate * (self.d_logistic(rating_pred)*(self.logistic(rating_pred)-self.train[i, j])*self.U[i, :])\n",
    "        \n",
    "        self.U[i, :] -= self.learning_rate * (self.lambda_U * self.U[i, :])\n",
    "        self.V[j, :] -= self.learning_rate * (self.lambda_V * self.V[j, :])\n",
    "        self.Z[k, :] -= self.learning_rate * (self.lambda_Z * self.Z[k, :])\n",
    "        \n",
    "        \n",
    "    \n",
    "    def get_complete_matrix(self):\n",
    "        \"\"\"\n",
    "        compute complete matrix\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.U.dot(self.V.T)\n",
    "    \n",
    "    \n",
    "    def print_results(self):\n",
    "        \"\"\"\n",
    "        print fit results\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"Final R matrix:\")\n",
    "        print(self.rescale_rate(self.get_complete_matrix()))\n",
    "        print(\"Final RMSE:\")\n",
    "        print(self.training_process[self.epochs-1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 10, train_cost = 0.2313, test_cost = 0.2313\n",
      "Iteration : 20, train_cost = 0.2278, test_cost = 0.2278\n",
      "Iteration : 30, train_cost = 0.2243, test_cost = 0.2243\n",
      "Iteration : 40, train_cost = 0.2206, test_cost = 0.2206\n",
      "Iteration : 50, train_cost = 0.2166, test_cost = 0.2166\n",
      "Iteration : 60, train_cost = 0.2122, test_cost = 0.2122\n",
      "Iteration : 70, train_cost = 0.2075, test_cost = 0.2075\n",
      "Iteration : 80, train_cost = 0.2024, test_cost = 0.2024\n",
      "Iteration : 90, train_cost = 0.1970, test_cost = 0.1970\n",
      "Iteration : 100, train_cost = 0.1914, test_cost = 0.1914\n",
      "Iteration : 110, train_cost = 0.1856, test_cost = 0.1856\n",
      "Iteration : 120, train_cost = 0.1798, test_cost = 0.1798\n",
      "Iteration : 130, train_cost = 0.1741, test_cost = 0.1741\n",
      "Iteration : 140, train_cost = 0.1688, test_cost = 0.1688\n",
      "Iteration : 150, train_cost = 0.1636, test_cost = 0.1636\n",
      "Iteration : 160, train_cost = 0.1587, test_cost = 0.1587\n",
      "Iteration : 170, train_cost = 0.1542, test_cost = 0.1542\n",
      "Iteration : 180, train_cost = 0.1503, test_cost = 0.1503\n",
      "Iteration : 190, train_cost = 0.1467, test_cost = 0.1467\n",
      "Iteration : 200, train_cost = 0.1434, test_cost = 0.1434\n",
      "Final R matrix:\n",
      "[[ 4.55228838  0.27405407  0.15984045  0.00546308  3.39612023  1.40241789\n",
      "   0.82514156  2.65488016]\n",
      " [ 4.51428501  0.43453888 -0.16691184 -0.11402887  3.69626275  1.42285673\n",
      "   0.93711942  2.59714274]\n",
      " [ 3.39336828  0.63208697  0.19811559  0.26961494  2.42533692  1.11277998\n",
      "   0.68537046  2.70893232]\n",
      " [ 1.21656614  1.04030625  0.96106582  1.06447621  0.94251153  0.94523206\n",
      "   0.93771359  1.23866517]\n",
      " [ 5.27394005  0.43197637 -0.39306691 -0.11653324  4.07777614  1.42380751\n",
      "   0.91126948  2.85905928]\n",
      " [ 5.02919505  0.44395058 -0.29862973 -0.53434679  3.70064451  1.47096247\n",
      "   0.81673931  4.13066273]]\n",
      "Final RMSE:\n",
      "0.14341829967358652\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    np.random.seed(7)\n",
    "    np.seterr(all=\"warn\")\n",
    "    \n",
    "    model = SoRec(train, train, trust, dim=5, learning_rate=0.01, epochs=200, verbose=True)\n",
    "    # regression parameter 2개\n",
    "    model.fit()\n",
    "    model.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mf_v1",
   "language": "python",
   "name": "mf_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
