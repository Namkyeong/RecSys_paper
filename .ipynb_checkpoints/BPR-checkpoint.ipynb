{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implementation of Bayesian Personalized Ranking for Implicit Feedback\n",
    "\n",
    "https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import data\n",
    "import random\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_100k = data.ml_100k\n",
    "train = data.train\n",
    "test = data.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization():\n",
    "    \n",
    "    def __init__(self, data, train, test, k, learning_rate, reg_param, epsilon):\n",
    "        \"\"\"\n",
    "        param R : Rating Matrix\n",
    "        param k : latent parameter\n",
    "        param learning_rate : alpha on weight update\n",
    "        param reg_param : regularization parameter\n",
    "        \"\"\"\n",
    "        \n",
    "        self._A_I = np.array(np.vectorize(lambda x: 0 if x==0 else 1)(data), dtype = np.float64)\n",
    "        self._X = np.array(np.vectorize(lambda x: 0 if x==0 else 1)(train), dtype = np.float64) # create X matrix : implicit feedbacks (binary)\n",
    "        self._X_test = np.array(np.vectorize(lambda x: 0 if x==0 else 1)(test), dtype = np.float64)\n",
    "        self._num_users, self._num_items = train.shape\n",
    "        self._k = k\n",
    "        self._learning_rate = learning_rate\n",
    "        self._reg_param = reg_param\n",
    "        self._epsilon = epsilon\n",
    "        \n",
    "        \n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        training Matrix Factorization : update matrix latent weight and bias\n",
    "        \"\"\"\n",
    "        \n",
    "        # init latent features\n",
    "        self._W = np.random.normal(scale = 1.0/self._k, size=(self._num_users, self._k))\n",
    "        self._H = np.random.normal(scale = 1.0/self._k, size=(self._num_items, self._k))\n",
    "        \n",
    "        \n",
    "        # train until cost converges\n",
    "        count = 0\n",
    "        self._training_process = []\n",
    "        for j in range(10):\n",
    "            start = timer()\n",
    "            for i in range(80000) :    \n",
    "\n",
    "                count += 1\n",
    "                # randomly choice _ Bootstrap\n",
    "                u = random.choice(self._X.nonzero()[0])\n",
    "                i = random.choice(self._X[u].nonzero()[0]) \n",
    "                j = random.choice(np.argwhere(self._X[u] == 0).T[0]) \n",
    "                self.gradient_descent(u, i, j)\n",
    "            print(\"complete 80000 iterations, time :%.4f\" % (timer()-start))\n",
    "\n",
    "            start_AUC = timer()\n",
    "            AUC = self.compute_AUC()\n",
    "            self._training_process.append((count, AUC))\n",
    "            print(\"Iteration : %d, AUC = %.4f, AUC computation time: %.4f\" % (count, AUC, timer()-start_AUC))\n",
    "\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        return sigmoid \n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    \n",
    "    \n",
    "    def gradient_descent(self, u, i, j):\n",
    "        \"\"\"\n",
    "        gradient descent function\n",
    "        param u : user index\n",
    "        param i : item index i\n",
    "        param j : item index j\n",
    "        \"\"\"\n",
    "        xuij_hat = self._W[u].dot(self._H[i].T) - self._W[u].dot(self._H[j].T)\n",
    "        sigmoid = self.sigmoid(xuij_hat) * np.exp(-xuij_hat)\n",
    "        self._W[u, :] += self._learning_rate * (sigmoid * (self._H[i] - self._H[j]) - self._reg_param * self._W[u])\n",
    "        self._H[i, :] += self._learning_rate * (sigmoid * self._W[u] - self._reg_param * self._H[i])\n",
    "        self._H[j, :] += self._learning_rate * (-1 * sigmoid * self._W[u] - self._reg_param * self._H[j])\n",
    "        \n",
    "        \n",
    "    def compute_AUC(self):\n",
    "        \n",
    "        self._X_hat = self._W.dot(self._H.T)\n",
    "        u_nonzero, i_nonzero = self._X_test.nonzero()\n",
    "        num = 0\n",
    "        \n",
    "        for u in u_nonzero :\n",
    "            temp = 0\n",
    "            temp_i = self._X_test[u].nonzero()[0]\n",
    "            temp_j = np.argwhere(self._A_I[u] == 0).T[0]\n",
    "            for i in temp_i :\n",
    "                for j in temp_j :\n",
    "                    if self._X_hat[u, i] > self._X_hat[u, j] :\n",
    "                        temp += 1\n",
    "            num += (temp / (len(temp_i)*len(temp_j)))\n",
    "        auc = num / len(u_nonzero)\n",
    "        \n",
    "        return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d9125d6c85e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# regression parameter 2개\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfactorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-0244a5336bdb>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;31m# randomly choice _ Bootstrap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "np.seterr(all=\"warn\")\n",
    "\n",
    "factorizer = MatrixFactorization(ml_100k, train, test, k=40, learning_rate=0.1, reg_param=0.01, epsilon = 0.1)\n",
    "\n",
    "# regression parameter 2개\n",
    "factorizer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mf_v1",
   "language": "python",
   "name": "mf_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
