{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select GPU Number\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if cuda available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.manual_seed(315)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(912)\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataframe.train\n",
    "test = dataframe.test\n",
    "ratings = dataframe.ratings\n",
    "user_pool = set(train[\"userId\"].unique()) # 6040\n",
    "item_pool = set(train[\"itemId\"].unique()) # 3706"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    torch.utils.data.Dataset 상속\n",
    "    \"\"\"\n",
    "    def __init__(self, user_tensor, item_tensor, neg_item_list):\n",
    "        self.user_tensor = user_tensor\n",
    "        self.item_tensor = item_tensor\n",
    "        self.neg_items = neg_item_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.user_tensor.size(0)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.user_tensor[index], self.item_tensor[index], self.neg_items[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user, test_item = [], []\n",
    "for i in range(len(test)):\n",
    "    test_user.append(test[\"userId\"][i])\n",
    "    test_item.append(test[\"itemId\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CML(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        \n",
    "        super(CML, self).__init__()\n",
    "        self.config = config\n",
    "        self.num_users = config[\"num_users\"]\n",
    "        self.num_items = config[\"num_items\"]\n",
    "        self.latent_dim = config[\"latent_dim\"]\n",
    "        self.margin = config[\"margin\"]\n",
    "        self.lambda_c = config[\"lambda_c\"]\n",
    "        \n",
    "        self.user_embedding = nn.Embedding(self.num_users, self.latent_dim, max_norm = 1) # restrict norms\n",
    "        self.item_embedding = nn.Embedding(self.num_items, self.latent_dim, max_norm = 1)\n",
    "        \n",
    "    \n",
    "    def distance_loss(self, i, j, k):\n",
    "        \"\"\"\n",
    "        compute distance loss\n",
    "        \"\"\"\n",
    "        \n",
    "        user = self.user_embedding(i).view(len(i), 1, self.latent_dim) # batchsize, X, latent_dim\n",
    "        item = self.item_embedding(j).view(len(i), 1, self.latent_dim)\n",
    "        neg_item = self.item_embedding(k)\n",
    "        d_ij = torch.cdist(user, item).view(-1, 1)**2 #(1024, 1)\n",
    "        d_ik = torch.cdist(user, neg_item).view(-1, 10)**2 #(1024, 10)\n",
    "        \n",
    "        metric = self.margin + d_ij - d_ik # (1024, 10)\n",
    "        loss = 0\n",
    "        for i in range(len(metric)):\n",
    "            temp_metric = metric[i][metric[i]>0]\n",
    "            rank_d_ij = 3676 * len(temp_metric) / 10\n",
    "            w_ij = np.log(rank_d_ij + 1)\n",
    "            loss +=  (w_ij * temp_metric).sum()\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def cov_loss(self):\n",
    "        \n",
    "        self.U = self.user_embedding(torch.LongTensor([x for x in range(self.num_users)]).cuda())\n",
    "        self.V = self.item_embedding(torch.LongTensor([x for x in range(self.num_items)]).cuda())\n",
    "        \n",
    "        matrix = torch.cat([self.U, self.V])\n",
    "        n_rows = matrix.shape[0]\n",
    "        matrix = matrix - torch.mean(matrix, dim=0)\n",
    "        cov = torch.matmul(matrix.T, matrix) / n_rows\n",
    "        loss = (torch.linalg.norm(cov) - torch.linalg.norm(torch.diagonal(cov),2))/self.num_users\n",
    "        \n",
    "        return loss * self.lambda_c\n",
    "    \n",
    "    \n",
    "    def create_train_dataset(self, train):\n",
    "        # change negative samples every epoch\n",
    "        train[\"negatives\"] = train[\"negative_items\"].apply(lambda x: random.sample(x, 10))\n",
    "        \n",
    "        users, items, neg_items = [], [], []\n",
    "        for row in train.itertuples():\n",
    "            users.append(int(row.userId))\n",
    "            items.append(int(row.itemId))\n",
    "            neg_items.append(row.negatives)\n",
    "\n",
    "        dataset = RatingDataset(user_tensor = torch.LongTensor(users),\n",
    "                            item_tensor = torch.LongTensor(items),\n",
    "                            neg_item_list = torch.LongTensor(neg_items))\n",
    "\n",
    "        return dataset, users, items\n",
    "    \n",
    "    \n",
    "    def evaluate(self, train_user, train_item, test_user, test_item):\n",
    "        \n",
    "        self.U = self.user_embedding(torch.LongTensor([x for x in range(self.num_users)]).cuda())\n",
    "        self.V = self.item_embedding(torch.LongTensor([x for x in range(self.num_items)]).cuda())\n",
    "        \n",
    "        x = torch.cdist(self.U, self.V)\n",
    "        for i, j in zip(train_user, train_item):\n",
    "            x[i, j] = 100\n",
    "        _, indices = x.topk(50, largest = False)\n",
    "        indices = indices.cpu().detach().numpy()\n",
    "        hit = 0\n",
    "        count = 0\n",
    "        for i in range(len(test_user)):\n",
    "            count += 1\n",
    "            if test_item[i] in indices[test_user[i]]:\n",
    "                hit += 1\n",
    "        \n",
    "        return hit/count\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CML_config = {\n",
    "    \"num_users\" : 6040,\n",
    "    \"num_items\" : 3706,\n",
    "    \"latent_dim\" : 64,\n",
    "    \"margin\" : 0.5,\n",
    "    \"lambda_c\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CML(CML_config).cuda()\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter(logdir=\"runs/CML_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1, total_loss = 16377129.3652, recall@50 = 0.1172, epoch_time = 328.3484sec\n",
      "epoch = 2, total_loss = 13476908.5210, recall@50 = 0.1194, epoch_time = 313.9404sec\n",
      "epoch = 3, total_loss = 12810498.1279, recall@50 = 0.1208, epoch_time = 334.9458sec\n",
      "epoch = 4, total_loss = 12347279.5552, recall@50 = 0.1268, epoch_time = 328.1542sec\n",
      "epoch = 5, total_loss = 11943090.9199, recall@50 = 0.1378, epoch_time = 328.8048sec\n",
      "epoch = 6, total_loss = 11526754.9414, recall@50 = 0.1504, epoch_time = 330.5499sec\n",
      "epoch = 7, total_loss = 11094218.7993, recall@50 = 0.1632, epoch_time = 328.2376sec\n",
      "epoch = 8, total_loss = 10683140.6270, recall@50 = 0.1753, epoch_time = 325.2598sec\n",
      "epoch = 9, total_loss = 10259980.1299, recall@50 = 0.1859, epoch_time = 331.0165sec\n",
      "epoch = 10, total_loss = 9845115.0210, recall@50 = 0.1946, epoch_time = 333.0186sec\n",
      "epoch = 11, total_loss = 9474069.7432, recall@50 = 0.2020, epoch_time = 328.5580sec\n",
      "epoch = 12, total_loss = 9120367.3672, recall@50 = 0.2085, epoch_time = 330.1409sec\n",
      "epoch = 13, total_loss = 8819443.0693, recall@50 = 0.2138, epoch_time = 328.9955sec\n",
      "epoch = 14, total_loss = 8540856.1421, recall@50 = 0.2189, epoch_time = 326.9715sec\n",
      "epoch = 15, total_loss = 8270358.6372, recall@50 = 0.2233, epoch_time = 327.3671sec\n",
      "epoch = 16, total_loss = 8057310.7900, recall@50 = 0.2272, epoch_time = 327.4036sec\n",
      "epoch = 17, total_loss = 7853834.2708, recall@50 = 0.2308, epoch_time = 328.6906sec\n",
      "epoch = 18, total_loss = 7676085.7952, recall@50 = 0.2341, epoch_time = 322.7217sec\n",
      "epoch = 19, total_loss = 7507973.1514, recall@50 = 0.2371, epoch_time = 322.5215sec\n",
      "epoch = 20, total_loss = 7356660.5396, recall@50 = 0.2401, epoch_time = 322.3182sec\n",
      "epoch = 21, total_loss = 7217412.8127, recall@50 = 0.2429, epoch_time = 323.0523sec\n",
      "epoch = 22, total_loss = 7092262.7937, recall@50 = 0.2454, epoch_time = 327.2180sec\n",
      "epoch = 23, total_loss = 6977384.1025, recall@50 = 0.2476, epoch_time = 326.2846sec\n",
      "epoch = 24, total_loss = 6872439.8108, recall@50 = 0.2499, epoch_time = 325.9760sec\n",
      "epoch = 25, total_loss = 6762631.8254, recall@50 = 0.2519, epoch_time = 323.3773sec\n",
      "epoch = 26, total_loss = 6676568.8071, recall@50 = 0.2536, epoch_time = 322.4370sec\n",
      "epoch = 27, total_loss = 6587414.5222, recall@50 = 0.2556, epoch_time = 320.7964sec\n",
      "epoch = 28, total_loss = 6505757.9358, recall@50 = 0.2575, epoch_time = 319.5767sec\n",
      "epoch = 29, total_loss = 6433880.5991, recall@50 = 0.2594, epoch_time = 319.8689sec\n",
      "epoch = 30, total_loss = 6358010.9773, recall@50 = 0.2609, epoch_time = 319.6327sec\n",
      "epoch = 31, total_loss = 6299803.9502, recall@50 = 0.2623, epoch_time = 318.9765sec\n",
      "epoch = 32, total_loss = 6236887.1047, recall@50 = 0.2636, epoch_time = 322.7250sec\n",
      "epoch = 33, total_loss = 6166510.5698, recall@50 = 0.2651, epoch_time = 321.5598sec\n",
      "epoch = 34, total_loss = 6119728.0781, recall@50 = 0.2667, epoch_time = 321.5905sec\n",
      "epoch = 35, total_loss = 6067110.4834, recall@50 = 0.2682, epoch_time = 321.0736sec\n",
      "epoch = 36, total_loss = 6011861.4990, recall@50 = 0.2692, epoch_time = 320.1381sec\n",
      "epoch = 37, total_loss = 5967298.4099, recall@50 = 0.2703, epoch_time = 317.2455sec\n",
      "epoch = 38, total_loss = 5915923.4375, recall@50 = 0.2717, epoch_time = 318.0142sec\n",
      "epoch = 39, total_loss = 5874077.6687, recall@50 = 0.2728, epoch_time = 319.2043sec\n",
      "epoch = 40, total_loss = 5831367.7251, recall@50 = 0.2737, epoch_time = 318.4155sec\n",
      "epoch = 41, total_loss = 5795741.2153, recall@50 = 0.2747, epoch_time = 315.9266sec\n",
      "epoch = 42, total_loss = 5756766.1494, recall@50 = 0.2756, epoch_time = 315.7137sec\n",
      "epoch = 43, total_loss = 5712460.3787, recall@50 = 0.2764, epoch_time = 317.0032sec\n",
      "epoch = 44, total_loss = 5682190.1479, recall@50 = 0.2769, epoch_time = 317.5117sec\n",
      "epoch = 45, total_loss = 5648525.9060, recall@50 = 0.2777, epoch_time = 318.7788sec\n",
      "epoch = 46, total_loss = 5621783.5601, recall@50 = 0.2787, epoch_time = 316.5429sec\n",
      "epoch = 47, total_loss = 5583425.1829, recall@50 = 0.2795, epoch_time = 316.1042sec\n",
      "epoch = 48, total_loss = 5559085.3484, recall@50 = 0.2799, epoch_time = 320.0302sec\n",
      "epoch = 49, total_loss = 5519582.3042, recall@50 = 0.2808, epoch_time = 320.4331sec\n",
      "epoch = 50, total_loss = 5490548.3286, recall@50 = 0.2815, epoch_time = 317.2847sec\n",
      "epoch = 51, total_loss = 5469790.4724, recall@50 = 0.2822, epoch_time = 315.8643sec\n",
      "epoch = 52, total_loss = 5451390.3943, recall@50 = 0.2828, epoch_time = 317.2824sec\n",
      "epoch = 53, total_loss = 5417957.4678, recall@50 = 0.2835, epoch_time = 316.1013sec\n",
      "epoch = 54, total_loss = 5395682.6133, recall@50 = 0.2840, epoch_time = 321.4050sec\n",
      "epoch = 55, total_loss = 5371555.4585, recall@50 = 0.2847, epoch_time = 320.6171sec\n",
      "epoch = 56, total_loss = 5356084.4819, recall@50 = 0.2853, epoch_time = 317.2791sec\n",
      "epoch = 57, total_loss = 5331254.9609, recall@50 = 0.2860, epoch_time = 318.7342sec\n",
      "epoch = 58, total_loss = 5308283.0293, recall@50 = 0.2862, epoch_time = 319.2582sec\n",
      "epoch = 59, total_loss = 5286312.8735, recall@50 = 0.2869, epoch_time = 318.1673sec\n",
      "epoch = 60, total_loss = 5266318.4646, recall@50 = 0.2874, epoch_time = 318.4323sec\n",
      "epoch = 61, total_loss = 5250265.8494, recall@50 = 0.2879, epoch_time = 320.7998sec\n",
      "epoch = 62, total_loss = 5234162.0078, recall@50 = 0.2884, epoch_time = 319.5445sec\n",
      "epoch = 63, total_loss = 5217845.6636, recall@50 = 0.2888, epoch_time = 300.1274sec\n",
      "epoch = 64, total_loss = 5192729.5181, recall@50 = 0.2891, epoch_time = 302.5519sec\n",
      "epoch = 65, total_loss = 5175625.1143, recall@50 = 0.2896, epoch_time = 301.0573sec\n",
      "epoch = 66, total_loss = 5162271.8826, recall@50 = 0.2900, epoch_time = 309.3633sec\n",
      "epoch = 67, total_loss = 5150328.1848, recall@50 = 0.2903, epoch_time = 317.2165sec\n",
      "epoch = 68, total_loss = 5124403.8528, recall@50 = 0.2906, epoch_time = 317.6681sec\n",
      "epoch = 69, total_loss = 5110051.8450, recall@50 = 0.2911, epoch_time = 317.5238sec\n",
      "epoch = 70, total_loss = 5098586.4863, recall@50 = 0.2913, epoch_time = 317.3487sec\n",
      "epoch = 71, total_loss = 5084118.7651, recall@50 = 0.2918, epoch_time = 320.8094sec\n",
      "epoch = 72, total_loss = 5077359.7251, recall@50 = 0.2922, epoch_time = 320.6194sec\n",
      "epoch = 73, total_loss = 5057967.7126, recall@50 = 0.2925, epoch_time = 316.4891sec\n",
      "epoch = 74, total_loss = 5045636.0061, recall@50 = 0.2928, epoch_time = 315.1721sec\n",
      "epoch = 75, total_loss = 5035092.2249, recall@50 = 0.2932, epoch_time = 316.2212sec\n",
      "epoch = 76, total_loss = 5017484.0034, recall@50 = 0.2935, epoch_time = 318.4965sec\n",
      "epoch = 77, total_loss = 5009249.6924, recall@50 = 0.2939, epoch_time = 322.8787sec\n",
      "epoch = 78, total_loss = 4987689.7454, recall@50 = 0.2942, epoch_time = 321.1695sec\n",
      "epoch = 79, total_loss = 4979826.3909, recall@50 = 0.2947, epoch_time = 317.3909sec\n",
      "epoch = 80, total_loss = 4968455.5930, recall@50 = 0.2950, epoch_time = 316.9749sec\n",
      "epoch = 81, total_loss = 4957663.3142, recall@50 = 0.2952, epoch_time = 321.3911sec\n",
      "epoch = 82, total_loss = 4943817.7568, recall@50 = 0.2955, epoch_time = 318.9334sec\n",
      "epoch = 83, total_loss = 4939717.9902, recall@50 = 0.2958, epoch_time = 323.7978sec\n",
      "epoch = 84, total_loss = 4924238.0503, recall@50 = 0.2961, epoch_time = 317.6042sec\n",
      "epoch = 85, total_loss = 4922435.3496, recall@50 = 0.2963, epoch_time = 314.6349sec\n",
      "epoch = 86, total_loss = 4901375.7563, recall@50 = 0.2967, epoch_time = 318.1178sec\n",
      "epoch = 87, total_loss = 4899102.0747, recall@50 = 0.2968, epoch_time = 319.5671sec\n",
      "epoch = 88, total_loss = 4889801.5078, recall@50 = 0.2969, epoch_time = 296.8224sec\n",
      "epoch = 89, total_loss = 4874387.7896, recall@50 = 0.2974, epoch_time = 297.7000sec\n",
      "epoch = 90, total_loss = 4870978.3770, recall@50 = 0.2975, epoch_time = 302.7817sec\n",
      "epoch = 91, total_loss = 4860559.8391, recall@50 = 0.2978, epoch_time = 304.7031sec\n",
      "epoch = 92, total_loss = 4839976.4927, recall@50 = 0.2982, epoch_time = 325.0740sec\n",
      "epoch = 93, total_loss = 4849400.1797, recall@50 = 0.2983, epoch_time = 327.5867sec\n",
      "epoch = 94, total_loss = 4833113.8496, recall@50 = 0.2984, epoch_time = 326.1590sec\n",
      "epoch = 95, total_loss = 4821423.6941, recall@50 = 0.2986, epoch_time = 330.7612sec\n",
      "epoch = 96, total_loss = 4809728.0042, recall@50 = 0.2988, epoch_time = 345.8688sec\n",
      "epoch = 97, total_loss = 4801118.8440, recall@50 = 0.2990, epoch_time = 327.7260sec\n",
      "epoch = 98, total_loss = 4795881.5432, recall@50 = 0.2993, epoch_time = 313.9623sec\n",
      "epoch = 99, total_loss = 4791571.1304, recall@50 = 0.2995, epoch_time = 313.1604sec\n",
      "epoch = 100, total_loss = 4783251.1584, recall@50 = 0.2996, epoch_time = 314.1521sec\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "training_process = []\n",
    "# epoch\n",
    "for epoch_id in range(1, num_epochs + 1):\n",
    "    dataset, users, items = model.create_train_dataset(train)\n",
    "    train_loader = DataLoader(dataset, batch_size = 1024, shuffle = True)\n",
    "    start_epoch = timer()\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        user, item, neg_items = batch[0], batch[1], batch[2]\n",
    "        user, item, neg_items = user.cuda(), item.cuda(), neg_items.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = model.distance_loss(user, item, neg_items) + model.cov_loss()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    recall_50 = model.evaluate(users, items, test_user, test_item)\n",
    "    writer.add_scalar(\"loss/training_loss\", total_loss, epoch_id)\n",
    "    writer.add_scalar(\"performance/recall@50\", recall_50, epoch_id)\n",
    "    print(\"epoch = {:d}, total_loss = {:.4f}, recall@50 = {:.4f}, epoch_time = {:.4f}sec\".format(epoch_id, total_loss, recall_50, timer()-start_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mf_v1",
   "language": "python",
   "name": "mf_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
