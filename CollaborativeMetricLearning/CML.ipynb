{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select GPU Number\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if cuda available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.manual_seed(315)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(912)\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataframe.train\n",
    "test = dataframe.test\n",
    "ratings = dataframe.ratings\n",
    "user_pool = set(train[\"userId\"].unique()) # 6040\n",
    "item_pool = set(train[\"itemId\"].unique()) # 3706"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    torch.utils.data.Dataset 상속\n",
    "    \"\"\"\n",
    "    def __init__(self, user_tensor, item_tensor, neg_item_list):\n",
    "        self.user_tensor = user_tensor\n",
    "        self.item_tensor = item_tensor\n",
    "        self.neg_items = neg_item_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.user_tensor.size(0)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.user_tensor[index], self.item_tensor[index], self.neg_items[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user, test_item = [], []\n",
    "for i in range(len(test)):\n",
    "    test_user.append(test[\"userId\"][i])\n",
    "    test_item.append(test[\"itemId\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CML(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        \n",
    "        super(CML, self).__init__()\n",
    "        self.config = config\n",
    "        self.num_users = config[\"num_users\"]\n",
    "        self.num_items = config[\"num_items\"]\n",
    "        self.latent_dim = config[\"latent_dim\"]\n",
    "        self.margin = config[\"margin\"]\n",
    "        self.lambda_c = config[\"lambda_c\"]\n",
    "        \n",
    "        self.user_embedding = nn.Embedding(self.num_users, self.latent_dim, max_norm = 1) # restrict norms\n",
    "        self.item_embedding = nn.Embedding(self.num_items, self.latent_dim, max_norm = 1)\n",
    "        \n",
    "    \n",
    "    def distance_loss(self, i, j, k):\n",
    "        \"\"\"\n",
    "        compute distance loss\n",
    "        \"\"\"\n",
    "        \n",
    "        user = self.user_embedding(i).view(len(i), 1, self.latent_dim) # batchsize, X, latent_dim\n",
    "        item = self.item_embedding(j).view(len(i), 1, self.latent_dim)\n",
    "        neg_item = self.item_embedding(k)\n",
    "        d_ij = torch.cdist(user, item).view(-1, 1)**2 #(1024, 1)\n",
    "        d_ik = torch.cdist(user, neg_item).view(-1, 10)**2 #(1024, 10)\n",
    "        \n",
    "        metric = self.margin + d_ij - d_ik # (1024, 10)\n",
    "        loss = 0\n",
    "        for i in range(len(metric)):\n",
    "            temp_metric = metric[i][metric[i]>0]\n",
    "            rank_d_ij = 3676 * len(temp_metric) / 10\n",
    "            w_ij = np.log(rank_d_ij + 1)\n",
    "            loss +=  (w_ij * temp_metric).sum()\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def cov_loss(self):\n",
    "        \n",
    "        self.U = self.user_embedding(torch.LongTensor([x for x in range(self.num_users)]).cuda())\n",
    "        self.V = self.item_embedding(torch.LongTensor([x for x in range(self.num_items)]).cuda())\n",
    "        \n",
    "        matrix = torch.cat([self.U, self.V])\n",
    "        n_rows = matrix.shape[0]\n",
    "        matrix = matrix - torch.mean(matrix, dim=0)\n",
    "        cov = torch.matmul(matrix.T, matrix) / n_rows\n",
    "        loss = (torch.linalg.norm(cov) - torch.linalg.norm(torch.diagonal(cov),2))/self.num_users\n",
    "        \n",
    "        return loss * self.lambda_c\n",
    "    \n",
    "    \n",
    "    def create_train_dataset(self, train):\n",
    "        # change negative samples every epoch\n",
    "        train[\"negatives\"] = train[\"negative_items\"].apply(lambda x: random.sample(x, 10))\n",
    "        \n",
    "        users, items, neg_items = [], [], []\n",
    "        for row in train.itertuples():\n",
    "            users.append(int(row.userId))\n",
    "            items.append(int(row.itemId))\n",
    "            neg_items.append(row.negatives)\n",
    "\n",
    "        dataset = RatingDataset(user_tensor = torch.LongTensor(users),\n",
    "                            item_tensor = torch.LongTensor(items),\n",
    "                            neg_item_list = torch.LongTensor(neg_items))\n",
    "\n",
    "        return dataset, users, items\n",
    "    \n",
    "    \n",
    "    def evaluate(self, train_user, train_item, test_user, test_item):\n",
    "        \n",
    "        self.U = self.user_embedding(torch.LongTensor([x for x in range(self.num_users)]).cuda())\n",
    "        self.V = self.item_embedding(torch.LongTensor([x for x in range(self.num_items)]).cuda())\n",
    "        \n",
    "        x = torch.cdist(self.U, self.V)\n",
    "        for i, j in zip(train_user, train_item):\n",
    "            x[i, j] = 100\n",
    "        _, indices = x.topk(50, largest = False)\n",
    "        indices = indices.cpu().detach().numpy()\n",
    "        hit = 0\n",
    "        count = 0\n",
    "        for i in range(len(test_user)):\n",
    "            count += 1\n",
    "            if test_item[i] in indices[test_user[i]]:\n",
    "                hit += 1\n",
    "        \n",
    "        return hit/count\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CML_config = {\n",
    "    \"num_users\" : 6040,\n",
    "    \"num_items\" : 3706,\n",
    "    \"latent_dim\" : 64,\n",
    "    \"margin\" : 0.5,\n",
    "    \"lambda_c\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CML(CML_config).cuda()\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter(logdir=\"runs/CML_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "training_process = []\n",
    "# epoch\n",
    "for epoch_id in range(1, num_epochs + 1):\n",
    "    dataset, users, items = model.create_train_dataset(train)\n",
    "    train_loader = DataLoader(dataset, batch_size = 1024, shuffle = True)\n",
    "    start_epoch = timer()\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        user, item, neg_items = batch[0], batch[1], batch[2]\n",
    "        user, item, neg_items = user.cuda(), item.cuda(), neg_items.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = model.distance_loss(user, item, neg_items) + model.cov_loss()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    recall_50 = model.evaluate(users, items, test_user, test_item)\n",
    "    writer.add_scalar(\"loss/training_loss\", total_loss, epoch_id)\n",
    "    writer.add_scalar(\"performance/recall@50\", recall_50, epoch_id)\n",
    "    print(\"epoch = {:d}, total_loss = {:.4f}, recall@50 = {:.4f}, epoch_time = {:.4f}sec\".format(epoch_id, total_loss, recall_50, timer()-start_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mf_v1",
   "language": "python",
   "name": "mf_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
